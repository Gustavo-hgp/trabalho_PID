{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection and Emotion Analysis with ESP32CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(frame):\n",
    "    \n",
    "    gray= cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "    face_rectangle = face_cascade.detectMultiScale(gray,1.3,5) \n",
    "    \n",
    "    for (x,y,w,h) in face_rectangle: \n",
    "        cv2.rectangle(frame, (x,y), (x+w,y+h), (0,255,0), 2) \n",
    "        \n",
    "    return frame\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"http://192.168.0.112:81/stream\") \n",
    "\n",
    "while True:\n",
    "    # Ler o frame do stream\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Falha ao capturar vídeo do ESP32-CAM\")\n",
    "        break\n",
    "\n",
    "    # Converter para escala de cinza (necessário para Haar Cascade)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detectar rostos\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    # Desenhar retângulos ao redor dos rostos\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "    # Exibir o vídeo redimensionado com a detecção\n",
    "    cv2.imshow('ESP32-CAM - Deteccao de Rosto', frame)\n",
    "\n",
    "    # Encerrar com a tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install deepface opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Caminho da imagem estática\n",
    "image_path = 'elon.jpg'  # Substitua pelo caminho da sua imagem\n",
    "\n",
    "# Carregar a imagem\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Converter a imagem de BGR (OpenCV) para RGB (Matplotlib)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Analisar expressões faciais usando DeepFace\n",
    "analysis = DeepFace.analyze(image, actions=['emotion'], enforce_detection=False)\n",
    "\n",
    "# Obter a emoção predominante\n",
    "emotion = analysis[0]['dominant_emotion']\n",
    "\n",
    "# Adicionar o texto da emoção na imagem\n",
    "cv2.putText(image_rgb, f'Emocao: {emotion}', (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "# Exibir a imagem com a emoção detectada usando Matplotlib\n",
    "plt.imshow(image_rgb)\n",
    "plt.axis('off')  # Desliga os eixos\n",
    "plt.title(f'Emoção Detectada: {emotion}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Usuario\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Endereço do ESP32-CAM\n",
    "esp32_url = 'http://192.168.0.112:81/stream'\n",
    "\n",
    "# Iniciar a captura de vídeo do ESP32-CAM\n",
    "cap = cv2.VideoCapture(esp32_url)\n",
    "\n",
    "while True:\n",
    "    # Ler o frame do stream\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Falha ao capturar vídeo do ESP32-CAM\")\n",
    "        break\n",
    "    \n",
    "       # Redimensionar o frame para melhorar o desempenho\n",
    "    frame_resized = cv2.resize(frame, (640, 480))  # Ajuste conforme necessário\n",
    "\n",
    "    try:\n",
    "        # Analisar expressões faciais usando DeepFace\n",
    "        analysis = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)\n",
    "\n",
    "        # Obter a emoção predominante (ajuste para a estrutura da saída)\n",
    "        emotion = analysis[0]['dominant_emotion']\n",
    "\n",
    "        # Exibir a emoção no frame\n",
    "        cv2.putText(frame, f'Emocao: {emotion}', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na análise: {e}\")\n",
    "\n",
    "    # Exibir o vídeo com a emoção detectada\n",
    "    cv2.imshow('Expressao Facial - ESP32-CAM', frame)\n",
    "\n",
    "    # Encerrar com a tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Envia uma requisição ao ESP32 notificando que o Python está lendo o stream\n",
    "def notify_start():\n",
    "    try:\n",
    "        response = requests.get(notification_url, params={\"status\": \"reading\"})\n",
    "        if response.status_code == 200:\n",
    "            print(\"Notificação enviada com sucesso!\")\n",
    "        else:\n",
    "            print(f\"Erro ao enviar notificação: {response.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro na requisição: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# Substitua pelo IP fornecido pelo ESP32-CAM no CameraWebServer\n",
    "stream_url = \"http://192.168.0.112:81/stream\"\n",
    "notification_url = \"http://192.168.0.112/notify\"  # Endpoint para notificação (modificar conforme necessário)\n",
    "\n",
    "\n",
    "# Imagem de referência para comparação (caminho para a imagem)\n",
    "reference_image_path = 'refereencia.png'\n",
    "\n",
    "# Gerar embeddings da imagem de referência\n",
    "reference_embedding = DeepFace.represent(reference_image_path, model_name='VGG-Face')[0]['embedding']\n",
    "\n",
    "# Iniciar a captura de vídeo do ESP32-CAM\n",
    "cap = cv2.VideoCapture(esp32_url)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Falha ao capturar vídeo do ESP32-CAM\")\n",
    "        break\n",
    "\n",
    "    frame_resized = cv2.resize(frame, (640, 480))\n",
    "    gray = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detectar rostos\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = frame_resized[y:y+h, x:x+w]  # Região de Interesse (ROI)\n",
    "\n",
    "        try:\n",
    "            # Gerar o embedding do rosto detectado\n",
    "            detected_embedding = DeepFace.represent(face_roi, model_name='VGG-Face',enforce_detection=False)[0]['embedding']\n",
    "            \n",
    "            # Comparar o embedding do rosto detectado com o embedding da imagem de referência\n",
    "            similarity = DeepFace.verify(face_roi, reference_image_path, model_name='Facenet512', enforce_detection=False)['distance']\n",
    "\n",
    "\n",
    "            # Exibir a semelhança\n",
    "            cv2.putText(frame_resized, f'Semelhanca: {similarity:.2f}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "            # Desenhar o retângulo ao redor do rosto\n",
    "            cv2.rectangle(frame_resized, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "            if similarity < 0.5:\n",
    "                # Notifica o ESP32 que o stream está sendo lido\n",
    "                notify_start()\n",
    "                time.sleep(5)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro na análise: {e}\")\n",
    "\n",
    "    # Exibir o vídeo com a semelhança do rosto\n",
    "    cv2.imshow('Comparacao de Rostos - ESP32-CAM', frame_resized)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
